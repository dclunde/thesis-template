\section{Workflow}
There are three main tasks when using CFD: meshing, simulation, and analysis. DSMC-PIC is a subsection of CFD; therefore, the original developers have designed systems for all three sections. However, most CFD analysis does not require the user to do all three tasks each time. A single mesh can produce many different simulations, and there can be many different analysis tasks from the same simulation. Therefore, SINATRA was broken down into three parts according to the three tasks it is able to accomplish. Each of those sections have their own repository, source code, and executables. They also share a resources repository between them. This allows the user to work in the meshing system and create the mesh or meshes necessary for their task. Then they move to the simulation system and use the newly created meshes as part of the simulation input. Once they have simulated the domain, they can take the created output files and run different analysis codes or create their own for their specific task.


% TO DO make sure that  cart3d has a 3d octree mesher
% TO DO - do I need trademark things here?

\begin{figure}
\includegraphics[width=.95\textwidth]{figures/UserWorkFlow.png}
\centering
\caption{Workflow System for SINATRA}
\label{fig:UserWorkFlow}
\end{figure}

\subsection{Mesh}
The original developers have designed this workflow for SINATRA while including the option for third party software to be used for the meshing and analysis sections. As seen in Figure \ref{fig:UserWorkFlow}, Cart3D\textsuperscript{TM} \footnote{Cart3D Documentation - \url{http://www.nanda.org/}} was chosen to be the meshing 3rd party additional tool. Meshing a domain for SINATRA requires an octree mesh. This capability is available within native SINATRA itself. The homegrown meshing tool is able to create an octree mesh with any user specified resolution. When an object is added to the domain, meshing becomes a much more complicated task (outside the scope and purpose of SINATRA). Cart3D\textsuperscript{TM} is a CFD analysis tool by NASA which is available to universities. It has within it a three-dimensional octree meshing tool, which can take geometries and domain sizing as inputs. SINATRA will take the outputted mesh and use it for simulations. Cart3D has not been tested with SINATRA. It has been slated for future work for another developer to fully integrate Cart3D\textsuperscript{TM} and geometry boundaries with SINATRA\footnote{It may be necessary to run Cart3D within a Linux\textsuperscript{TM} virtual box for Windows\textsuperscript{TM} users}. This thesis uses the homegrown meshing tool exclusively. \par

\subsection{Simulation}

SINATRA has been designed to be simple to develop and execute. Execution is completed through one executable file and one input text file. For simplicity, Windows\textsuperscript{TM} users can drag the .txt file onto the .exe file to run the simulation. It can also be run through the command line with the path to an input file as the command line argument, or if the argument is missing SINATRA will request the user to input the filepath. The executable and output do not depend on using a specific Integrated Developer Environment like Visual Studio\textsuperscript{TM} or even using a certain operating system A user can run many simulations or string together meshing, simulating, and analysis simply through a batch script. An example script is shown in Appendix \ref{app:examplescript}. \par
\indent SINATRA was also deliberately built to be machine independent to reduce the risk of the code not being developed further or used for new tasks. This was accomplished through making compilation very simple. It requires only a single command with no additional libraries\footnote{Need OpenMP\textsuperscript{TM} for parallelization}. There are sample compile statements in the ReadME and compile scripts, but even an intermediate C++ developer could figure out how to compile SINATRA from the file list alone. This helps new developers move quickly through the code learning phase and can even allow beginners to explore the code base and test more complicated features. SINATRA has been tested through being compiled with various compilers and on different operating systems. 

% TO DO add ppt graphic of this codeflow one with all the files and titles - appendix


\subsection{Analysis}
% TO DO make analysis functions which gooes through all the cells (send anamynous function)


 After the simulation phase is completed, the user can use the SINATRA output files for analysis. The original developers created MATLAB\textsuperscript{\textregistered} scripts within SINATRA to perform basic types of analysis. For other analysis, Tecplot 360\textsuperscript{TM} \footnote{Tecplot 360 CFD post processing tools to analyzedata - \url{https://www.tecplot.com/products/tecplot-360/}} has been chosen as a third party tool. Tecplot\textsuperscript{TM} is a specific CFD analysis and visualization tool, which can show the mesh, geometry, and fluid flow. It includes robust visualization and animation tools as well as various analysis functions. SINATRA can output data in a format that Tecplot\textsuperscript{TM} reads natively. Tecplot\textsuperscript{TM} and SINATRA's integration has been tested and used by the first developers.\par
 \indent SINATRA's analysis section has not been built with an encompassing set of features to complete any task. It is up to the future users to determine the analysis they need to accomplish, edit SINATRA's output class to accommodate, and compile the output data into the format best suited the situation. This can be completed through looking at SINATRA's output class and reformatting other analysis techniques for the task at hand. Tecplot\textsuperscript{TM} and the included MATLAB\textsuperscript{\textregistered} scripts can do a majority of the beginning analysis, but the most detailed tools will need to be built by new developers.

 
\subsection{Execution Time}
\label{sec:execution}
A DSMC code is by nature a very computationally intense program. It requires a large amount of memory to store all of the data of each particle and mesh cell. It requires a lot of computational power to calculate the movement and collisions, therefore, it is important to design the code to be efficient and powerful. This is why C++ and classes were chosen for SINATRA; however, it is still a slow simulation for a large meshes with high particle densities. It is slated as future work for a developer who specializes in computer science and computational optimization to reduce the execution time of large SINATRA runs. However, there are a few bottlenecks which were removed by the author. This improvement helps manage simulation time, especially when the Poisson equation solver is included. \par

\indent The simplest and most effective way to reduce simulation time on a DSMC simulation is parallelization. Parallelization is a complex and involved field with many competing ideas on best practices. There are many discussions about best ways to parallelize DSMC codes and PIC codes. Parallelization itself is also on the forefront of new technology at the time of this thesis. Moore's law has allowed programmers to have a large amount of memory for their simulation, so that is rarely the constricting factor. Processors seem to be approaching an asymptote in terms of their power for user made systems on languages like C++. Breaking the simulation between multiple cores or even within the graphics processing unit (GPU) seems to be the new normal for decreasing execution times. For SINATRA, there are many parallelization possibilities. It is slated for future work for another developer to optimize the parallelization capacity. At this time, simple parallelization has been developed by the author. During the particle propagation phase, there is no interaction between the commands, therefore, it can be parallelized by using the library OpenMP\textsuperscript{TM} \footnote{Home - OpenMP - \url{https://www.openmp.org/}}. This was completed through first identifying the loop in the simulation which moves each particle. Then the loop is reformatted to remove dependencies on any variables which must be updated sequentially. This allows the simulation to run in many different cores without interfering with the other cores. Finally, debugging is preformed to find any errors like segmentation faults and pointer errors. Parallization has been implemented into the input file. It can be enabled through an optional keyword in the input file and ensuring the library is included in the compile statement. \par


\begin{figure}
\includegraphics[width=.55\textwidth]{figures/HPC_cluster.png}
\centering
\caption[System Architecture of Cal Poly HPC Cluster]{System Architecture of Cal Poly HPC Cluster \textmd{\cite{hpc}}}
\label{fig:hpccluser}
\end{figure}


\indent The Aerospace Department at Cal Poly, SLO owns a server that is available to aerospace students and faculty. It is referred to as Bishop High Performing Cluster \cite{hpc}. It includes a workload manager so that each user only needs to submit their jobs and they are separated through the different nodes on the cluster. The cluster allows each full user 48 cores and 64 GB of Ram \cite{hpc}. This is critical to SINATRA. Through the parallelization the simulation can be run in parallel on the server. Not only does Bishop have quick processors, but it also has the 48 cores between which the simulation can be broken up. This enables the execution time of a large simulation to be cut down by significant amounts, seen in Table \ref{tab:Timing}. This server also allows users to run simulations off of their local machines, which helps compartmentalize heavy simulation runs from everyday tasks. It also allows scheduling of multiple simulations such that large analysis tasks can be completed without human interface. SINATRA has been made with the Bishop cluster as an expected resource. \par

\indent Another simple process to reduce the execution time is during the linking phase. After the particles are created, they must be associated with the cells that they are in. To do this it requires a nested for loop  through all particles inside all cells. This is a very slow process. In order to increase the speed, it is possible to allow the linking process to ignore the particles it has already linked and ones which aren't in the domain. This has been been implemented by the author, however, there is a simpler solution. There is an option in SINATRA to seed particles in a uniformly random way \cite{Galvez2018a}. This method creates the same number of particles in each cell but randomly distributes them within the cell. With uniform initialization, the linking process can be removed completely, and the execution time is significantly reduced. This has been implemented by the author. This was completed through reformatting how particles are created in SINATRA. A new constructor for particles was created which includes the index of the cell which it was created in as well as the index of the next particle for the particle chain. The other constructors for particles are updated so that they explicitly state that they are not yet linked to a cell and don't know their next particle. These are two main things are what are added to the particle object during linking. Then during initialization, the cells are given the information of their first particle and the total number of particles in this cell. These two things are what are added to the cells during linking. These two changes allow linking to be removed for the uniform initialization case. \par

\begin{table}
\caption{Execution Time Comparisons}
\label{tab:Timing}
\vspace{0.3cm}
\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
                             & First Iteration & Time-step Average & Total Time     \\ \hline
Parallel and No Linking & 9 sec           & 10 sec           & 1 min, 38 sec  \\ \hline
Serial and No Linking   & 3 min, 23 sec   & 3 min, 23 sec    & 33 min, 50 sec \\ \hline
Serial and Linking      & 15 min, 1 sec   &  3 min, 58 sec   &   50 min, 47 sec             \\ \hline
\end{tabular}
\end{center}
\end{table}

\indent A simple timing comparison was completed to examine the effectiveness of two execution time reduction methods. A collision-less simulation with all diffuse walls was run on the HPC server. The simulation used 32768 Cells, \(5 \times 10^{19}\) real to simulated particles, \(1 \times 10^{26}\) number density which gives 2 million simulation particles in the domain, and 10 time-steps of \(1 \times 10^{-8}\) seconds with 0 m/s stream velocity and 300 Kelvin temperature. As seen in Table \ref{tab:Timing}, including these optimization techniques has reduced the simulation time by 49 minutes for this simulation. By removing the linking process, we were able to save a large amount of time during the set up\footnote{There is a slight difference in the iteration time for the linking and no linking runs because the no linking run did not use the uniform initialization because uniform initialization has has the linking section bypassed in the current version.}. Also, by adding the simple parallelization we were able to reduce the simulation time by 95\%, from over 50 minutes to under 2 minutes. These two techniques combined make an appreciable difference in the execution time. They allow more complicated simulations to be run within the same amount of computation time. This allows the user to run longer simulations or multiple in order to increase confidence in the accuracy of the solution, as well as reduce the variance caused by the randomness in a DSMC simulation. \par

\indent Finally, an important tool for execution time analysis is debugging and profiling. It is important while developing software to have the ability to debug the code to see exactly what it is doing. This is usually achieved through the Integrated development environment (IDE); however, in an effort to make SINATRA IDE independent, the code has built in a method which allows the GNU Project Debugger to be used on the code\footnote{GDB: The GNU Project Debugger - \url{https://www.gnu.org/software/gdb/}}. This is a command line interface for g++ compiled executables. It is a legacy debugger that is well documented and is included in most installations of the g++ compiler. Using gdb on SINATRA allowed the author to solve problems within various improvements including removing linking and adding parallelized code. Secondly, a profiler allows the user to view exactly how often each line of code is run, how long it takes to run, and the sub processes, which contributes to that execution time. This is a strong way to identify simple coding bottlenecks and optimizing the coding time. The author has set up the compiling and code base in order to fit with the profilier Very Sleepy\textsuperscript{TM} \footnote{Very Sleepy documentation - \url{http://www.codersnotes.com/sleepy/}}. This was completed by determining the version of g++ which the profiler required, compiling in that method, and then allowing the profiler to access the executable. Very Sleepy\textsuperscript{TM} is a light and simple profiler which shows each line of the source code and the timing involved. By setting up SINATRA to be widely compatible it allowed these developing tools to push SINATRA towards an industry standard level. \par


% Cite processer information
% Cite DSMC paralization papers

